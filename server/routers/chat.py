#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
èŠå¤©å¯¹è¯ API - æ”¯æŒ SSE æµå¼è¾“å‡º
"""

import sys
import os
import json
import time
import asyncio
import requests

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
import sqlite3
from datetime import datetime


from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, AsyncGenerator

# å¯¼å…¥ç°æœ‰æ¨¡å—
from modules.intent_classifier import IntentClassifier
from modules.db_query import TaxIncentiveQuery
from modules.deepseek_client import DeepSeekClient
from modules.financial_query import FinancialQuery

# è®¤è¯ä¾èµ–é¡¹
from server.routers.auth import get_current_user

router = APIRouter()

# Coze API é…ç½®ï¼ˆä»åŸ coze_chat.py è¿ç§»ï¼‰
PAT_TOKEN = "pat_6IkhWiD17bW1qZmXHzeKPPU2YZzBQG8OlqyUyUSXlEFIGBPfOYlTsPK5VHjUSPz8"
BOT_ID = "7592905400907989034"
USER_ID = "123"

# å…¨å±€æ¨¡å—å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_classifier = None
_db_query = None
_deepseek = None
_financial_query = None

# æ•°æ®åº“è·¯å¾„
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
USERS_DB_PATH = os.path.join(BASE_DIR, "database", "users.db")
FINANCIAL_DB_PATH = os.path.join(BASE_DIR, "database", "financial.db")

def save_message(user_id: str, role: str, content: str, type: str = 'text'):
    """ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“"""
    try:
        conn = sqlite3.connect(USERS_DB_PATH)
        cursor = conn.cursor()
        cursor.execute(
            "INSERT INTO chat_messages (user_id, role, content, type) VALUES (?, ?, ?, ?)",
            (user_id, role, content, type)
        )
        conn.commit()
    except Exception as e:
        print(f"Error saving message: {e}")
    finally:
        if conn:
            conn.close()

def get_chat_history(user_id: str, limit: int = 50):
    """è·å–èŠå¤©å†å² (ä¸»çª—å£æ¶ˆæ¯ï¼Œè¿‡æ»¤å·²åˆ é™¤çš„)"""
    try:
        conn = sqlite3.connect(USERS_DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute(
            "SELECT * FROM chat_messages WHERE user_id = ? AND visible_in_chat = 1 ORDER BY created_at ASC LIMIT ?",
            (user_id, limit)
        )
        rows = cursor.fetchall()
        return [dict(row) for row in rows]
    except Exception as e:
        print(f"Error getting history: {e}")
        return []
    finally:
        if conn:
            conn.close()

def get_history_items(user_id: str, limit: int = 50):
    """è·å–å†å²è®°å½•åˆ—è¡¨ (ä¾§è¾¹æ ï¼Œè¿‡æ»¤å·²åˆ é™¤çš„)"""
    try:
        conn = sqlite3.connect(USERS_DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute(
            "SELECT DISTINCT content FROM chat_messages WHERE user_id = ? AND role = 'user' AND visible_in_history = 1 ORDER BY created_at DESC LIMIT ?",
            (user_id, limit)
        )
        rows = cursor.fetchall()
        return [row['content'] for row in rows]
    except Exception as e:
        print(f"Error getting history items: {e}")
        return []
    finally:
        if conn:
            conn.close()

def delete_user_history(user_id: str, message_ids: Optional[list] = None, target: str = "chat"):
    """åˆ é™¤èŠå¤©å†å² (è½¯åˆ é™¤)
    
    Args:
        user_id: ç”¨æˆ·ID
        message_ids: è¦åˆ é™¤çš„æ¶ˆæ¯IDåˆ—è¡¨ï¼Œä¸ºç©ºåˆ™åˆ é™¤å…¨éƒ¨
        target: "chat" åˆ é™¤ä¸»çª—å£æ¶ˆæ¯, "history" åˆ é™¤ä¾§è¾¹æ å†å²è®°å½•
    """
    try:
        conn = sqlite3.connect(USERS_DB_PATH)
        cursor = conn.cursor()
        
        # ç¡®å®šè¦æ›´æ–°çš„å­—æ®µ
        if target == "history":
            visibility_column = "visible_in_history"
        else:
            visibility_column = "visible_in_chat"
        
        if message_ids:
            # Soft delete specific messages
            placeholders = ','.join('?' for _ in message_ids)
            cursor.execute(
                f"UPDATE chat_messages SET {visibility_column} = 0 WHERE user_id = ? AND id IN ({placeholders})",
                (user_id, *message_ids)
            )
        else:
            # Soft delete all
            cursor.execute(f"UPDATE chat_messages SET {visibility_column} = 0 WHERE user_id = ?", (user_id,))
        conn.commit()
    except Exception as e:
        print(f"Error deleting history: {e}")
    finally:
        if conn:
            conn.close()

def delete_history_by_content(user_id: str, content_list: list):
    """æŒ‰å†…å®¹åˆ é™¤å†å²è®°å½• (ç”¨äºä¾§è¾¹æ åˆ é™¤)"""
    try:
        conn = sqlite3.connect(USERS_DB_PATH)
        cursor = conn.cursor()
        for content in content_list:
            cursor.execute(
                "UPDATE chat_messages SET visible_in_history = 0 WHERE user_id = ? AND role = 'user' AND content = ?",
                (user_id, content)
            )
        conn.commit()
    except Exception as e:
        print(f"Error deleting history by content: {e}")
    finally:
        if conn:
            conn.close()


def get_modules():
    """è·å–æˆ–åˆå§‹åŒ–æ¨¡å—å®ä¾‹"""
    global _classifier, _db_query, _deepseek, _financial_query
    
    if _classifier is None:
        _classifier = IntentClassifier(use_llm=True)
        _db_query = TaxIncentiveQuery()
        _deepseek = DeepSeekClient()
        _financial_query = FinancialQuery()
    
    return _classifier, _db_query, _deepseek, _financial_query


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    question: str
    company_id: Optional[int] = None
    enable_routing: bool = True
    show_chart: bool = True  # æ–°å¢: æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨
    response_mode: str = "detailed"  # æ–°å¢: å›ç­”æ¨¡å¼ (detailed/concise)


class ChatResponse(BaseModel):
    """éæµå¼èŠå¤©å“åº”"""
    content: str
    source: str  # "tax_incentive", "financial", "coze"


# è´¢åŠ¡å…³é”®è¯åˆ—è¡¨ï¼ˆä» coze_chat.py è¿ç§»ï¼‰
FINANCIAL_KEYWORDS = [
    # åˆ©æ¶¦è¡¨ç›¸å…³
    "é”€å”®é¢", "æ”¶å…¥", "è¥ä¸šæ”¶å…¥", "è¥æ”¶", "æ€»æ”¶å…¥",
    "åˆ©æ¶¦", "å‡€åˆ©æ¶¦", "è¥ä¸šåˆ©æ¶¦", "æ¯›åˆ©", "åˆ©æ¶¦æ€»é¢", "ç¨å‰åˆ©æ¶¦",
    "æˆæœ¬", "è¥ä¸šæˆæœ¬", "é”€å”®æˆæœ¬", "ä¸»è¥ä¸šåŠ¡æˆæœ¬",
    "è´¹ç”¨", "é”€å”®è´¹ç”¨", "ç®¡ç†è´¹ç”¨", "è´¢åŠ¡è´¹ç”¨", "è¡Œæ”¿è´¹ç”¨", "åˆ©æ¯è´¹ç”¨",
    "ç¨é‡‘åŠé™„åŠ ", "é™„åŠ ç¨", "æ‰€å¾—ç¨è´¹ç”¨", "æ‰€å¾—ç¨", "ä¼ä¸šæ‰€å¾—ç¨",
    
    # èµ„äº§è´Ÿå€ºè¡¨ç›¸å…³
    "èµ„äº§", "æ€»èµ„äº§", "èµ„äº§æ€»é¢", "è´Ÿå€º", "æ€»è´Ÿå€º", "è´Ÿå€ºæ€»é¢",
    "æƒç›Š", "æ‰€æœ‰è€…æƒç›Š", "å‡€èµ„äº§", "è‚¡ä¸œæƒç›Š",
    "å­˜è´§", "åº“å­˜", "åº”æ”¶è´¦æ¬¾", "åº”ä»˜è´¦æ¬¾",
    "æµåŠ¨èµ„äº§", "æµåŠ¨è´Ÿå€º", "ç°é‡‘", "é“¶è¡Œå­˜æ¬¾",
    
    # è´¢åŠ¡æŒ‡æ ‡ç›¸å…³
    "æ¯›åˆ©ç‡", "å‡€åˆ©ç‡", "å‡€åˆ©æ¶¦ç‡", "åˆ©æ¶¦ç‡",
    "èµ„äº§è´Ÿå€ºç‡", "è´Ÿå€ºç‡", "æµåŠ¨æ¯”ç‡", "é€ŸåŠ¨æ¯”ç‡",
    "ROA", "ROE", "roa", "roe", "æ€»èµ„äº§æ”¶ç›Šç‡", "å‡€èµ„äº§æ”¶ç›Šç‡",
    "å‘¨è½¬ç‡", "å‘¨è½¬å¤©æ•°", "å­˜è´§å‘¨è½¬ç‡", "åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡",
    "å¢é•¿ç‡", "è¥æ”¶å¢é•¿ç‡", "åˆ©æ¶¦å¢é•¿ç‡",
    
    # çº³ç¨ç›¸å…³
    "åº”çº³ç¨é¢", "ç¨è´Ÿç‡", "å¢å€¼ç¨ç¨è´Ÿ", "å¢å€¼ç¨", "æ‰€å¾—ç¨é¢",
    
    # é€šç”¨æŸ¥è¯¢è¯
    "å¤šå°‘", "æ˜¯å¤šå°‘", "æ•°æ®", "é‡‘é¢", "æŸ¥è¯¢", "å¢é•¿", "å˜åŒ–", "è¶‹åŠ¿", "æƒ…å†µ"
]


def has_financial_keywords(question: str) -> bool:
    """æ£€æŸ¥é—®é¢˜æ˜¯å¦åŒ…å«è´¢åŠ¡å…³é”®è¯"""
    return any(kw in question for kw in FINANCIAL_KEYWORDS)


async def generate_sse_response(
    question: str, 
    user_id: str,
    company_id: Optional[int] = None,
    enable_routing: bool = True,
    show_chart: bool = True,
    response_mode: str = "detailed"
) -> AsyncGenerator[str, None]:
    """
    ç”Ÿæˆ SSE æµå¼å“åº”
    
    Yields:
        SSE æ ¼å¼çš„æ¶ˆæ¯: "data: {json}\n\n"
    """
    classifier, db_query, deepseek, financial_query = get_modules()
    
    def send_event(event_type: str, data: dict) -> str:
        """æ ¼å¼åŒ– SSE äº‹ä»¶"""
        return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"
    
    def send_content(content: str) -> str:
        """å‘é€å†…å®¹ç‰‡æ®µ"""
        return send_event("message", {"content": content})
    

    try:
        # å‘é€å¼€å§‹äº‹ä»¶
        yield send_event("start", {"status": "processing"})
        
        # è·å–å…¬å¸ä¿¡æ¯
        company = None
        if company_id:
            import sqlite3
            conn = sqlite3.connect(FINANCIAL_DB_PATH)
            cursor = conn.cursor()
            cursor.execute("SELECT id, name FROM companies WHERE id = ?", (company_id,))
            row = cursor.fetchone()
            conn.close()
            if row:
                company = {"id": row[0], "name": row[1]}
        # 4. ä¿å­˜å®Œæ•´çš„ AI å›ç­”
        # (æ­¤æ—¶ stream_financial_response ç­‰å·²æ‰§è¡Œå®Œæ¯•ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§æœºåˆ¶æ•è·äº§ç”Ÿçš„å†…å®¹)
        # ç”±äºæ˜¯æµå¼è¿”å›ï¼Œä¸Šé¢çš„ç”Ÿæˆå™¨å·²ç»åœ¨ yield å†…å®¹ã€‚
        # æˆ‘ä»¬éœ€è¦åœ¨ç”Ÿæˆå™¨å†…éƒ¨æ”¶é›†å®Œæ•´å†…å®¹ï¼Œæˆ–è€…åœ¨ yield ä¹‹åä¿å­˜ã€‚
        # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ä¿®æ”¹ç”Ÿæˆå™¨å‡½æ•°ï¼Œè®©å®ƒä»¬è´Ÿè´£ä¿å­˜ï¼Œæˆ–è€…ä½¿ç”¨ä¸€ä¸ªç´¯åŠ å™¨ã€‚
        
        # æ›´å¥½çš„æ–¹å¼ï¼šé‡æ–°è®¾è®¡ stream_functions è®©å®ƒä»¬è¿”å›å®Œæ•´å†…å®¹ï¼Œ
        # ä½†è¿™é‡Œæ˜¯ generatorã€‚
        # æ–¹æ¡ˆï¼šåœ¨å„ä¸ª internal stream å‡½æ•°ä¸­ç»´æŠ¤ full_content å¹¶ä¿å­˜ã€‚
        # é‰´äºä»£ç ç»“æ„ï¼Œæˆ‘ä»¬åœ¨æœ¬å‡½æ•°(generate_sse_response)æ— æ³•ç›´æ¥è·å–å­ç”Ÿæˆå™¨çš„ç´¯ç§¯å†…å®¹ï¼Œ
        # é™¤éå­ç”Ÿæˆå™¨ yield ç‰¹æ®Šäº‹ä»¶æˆ–è€…æˆ‘ä»¬ä¼ å…¥ callbackã€‚
        
        # è®©æˆ‘ä»¬æŠŠ save_message é€»è¾‘æ”¾åœ¨ start event ä¹‹å (ä¿å­˜ç”¨æˆ·é—®é¢˜)
        save_message(user_id, "user", question)
        
        full_response_content = ""

        # è·¯ç”±é€»è¾‘-ä¿®æ”¹ä¸ºæ•è·å†…å®¹
        if not enable_routing:
             # Coze API
            yield send_event("route", {"path": "coze"})
            async for chunk in stream_coze_response(question):
                # è§£æ chunk è·å– content
                # chunk æ ¼å¼: "event: message\ndata: {"content": "..."}\n\n"
                if "content" in chunk:
                    try:
                        # ç®€å•çš„å­—ç¬¦ä¸²æå–ï¼Œå¥å£®æ€§ä¸€èˆ¬ä½†æœ‰æ•ˆ
                        import re
                        match = re.search(r'"content":\s*"(.*)"\}', chunk)
                        if match:
                             # è¿™ç§æå–å¯¹è½¬ä¹‰å­—ç¬¦å¤„ç†ä¸å¥½ï¼Œæœ€å¥½è§£æ JSON
                             pass
                        # Better: re-parse json
                        lines = chunk.strip().split('\n')
                        for line in lines:
                            if line.startswith('data:'):
                                data = json.loads(line[5:])
                                if 'content' in data:
                                    full_response_content += data['content']
                    except:
                        pass
                yield chunk
        else:
            # ... ç°æœ‰é€»è¾‘ ...
            # ä¸ºäº†æ•è·å†…å®¹ï¼Œæˆ‘ä»¬éœ€è¦åŒ…è£…ä¸€ä¸‹ yield
            
            # å®šä¹‰ä¸€ä¸ªå†…éƒ¨ç”Ÿæˆå™¨æ¥ä»£ç† iterate
            async def content_capturer(generator):
                nonlocal full_response_content
                async for chunk in generator:
                    # å°è¯•è§£æ content ç”¨äºä¿å­˜
                    # chunk å¯èƒ½æ˜¯ message, route, chart, summary ç­‰
                    try:
                        lines = chunk.strip().split('\n')
                        event_type = None
                        for line in lines:
                            if line.startswith('event:'):
                                event_type = line[6:].strip()
                            if line.startswith('data:'):
                                data = json.loads(line[5:])
                                if event_type == 'message' and 'content' in data:
                                    full_response_content += data['content']
                                elif event_type == 'summary' and 'content' in data:
                                    full_response_content += f"\n\n**æ€»ç»“**:\n{data['content']}"
                                # Chart æ•°æ®æ¯”è¾ƒå¤æ‚ï¼Œæš‚æ—¶åªä¿å­˜æ–‡æœ¬æè¿°æˆ–ç‰¹æ®Šæ ‡è®°
                                # å¦‚æœè¦ä¿å­˜å›¾è¡¨ï¼Œéœ€è¦åœ¨ database å¢åŠ å­—æ®µæˆ–è€…æŠŠ chart json å­˜å…¥ content
                                elif event_type == 'chart':
                                    # å°†å›¾è¡¨æ•°æ®ä½œä¸ºç‰¹æ®Šæ ‡è®°å­˜å…¥æ–‡æœ¬ï¼Œæˆ–è€…åç»­å‰ç«¯è§£æ
                                    # è¿™é‡Œç®€å•è®°å½• [å›¾è¡¨] å ä½ç¬¦ï¼Œæˆ–è€…ä¿å­˜ raw json
                                    # ä¸ºäº†å‰ç«¯èƒ½æ¢å¤ï¼Œæœ€å¥½ä¿å­˜ raw json åˆ° content (mixin) 
                                    # æˆ–è€… æ•°æ®åº“åŒºåˆ† type
                                    # ç®€å•èµ·è§ï¼šæˆ‘ä»¬å°† chart data json åºåˆ—åŒ–è¿½åŠ åˆ° contentï¼Œ
                                    # å¹¶ç”¨ç‰¹æ®Šåˆ†éš”ç¬¦ï¼Œæˆ–è€…å‰ç«¯ä¾é  content é‡Œçš„ markdownã€‚
                                    # ä½† chart æ˜¯ç»“æ„åŒ–æ•°æ®ã€‚
                                    # ä¿®æ”¹ chat_messages è¡¨ç»“æ„æ”¯æŒ json data æœ€å¥½ï¼Œ
                                    # ä½†ç°åœ¨è¡¨åªæœ‰ content (text).
                                    # è®©æˆ‘ä»¬æŠŠ Chart JSON append åˆ° content åé¢ï¼Œç”¨ç‰¹æ®Šæ ‡è®°åŒ…è£¹
                                    # <CHART_DATA>json</CHART_DATA>
                                    full_response_content += f"\n\n<CHART_DATA>{json.dumps(data, ensure_ascii=False)}</CHART_DATA>\n\n"
                    except:
                        pass
                    yield chunk

            # æ„å›¾è¯†åˆ«
            intent = classifier.classify(question)
            
            # ... (çœç•¥ä¸­é—´é‡å¤ä»£ç , åªåœ¨æ­¤å¤„åšé€»è¾‘åˆ†æ”¯) ...
            if intent == "other" and company and has_financial_keywords(question):
                intent = "financial_data"
                
            path_name = "financial" if intent == "financial_data" else intent
            yield send_event("route", {"path": path_name, "company": company["name"] if company else None})
            
            if intent == "financial_data":
                async for chunk in content_capturer(stream_financial_response(question, company, financial_query, deepseek, show_chart, response_mode)):
                    yield chunk
            elif intent == "tax_incentive":
                async for chunk in content_capturer(stream_tax_response(question, db_query, deepseek)):
                    yield chunk
            else:
                async for chunk in content_capturer(stream_coze_response(question)):
                    yield chunk

        # Generation Complete: Save Assistant Message
        if full_response_content:
            save_message(user_id, "assistant", full_response_content)

    except Exception as e:
        yield send_event("error", {"message": str(e)})
    
    finally:
        yield send_event("done", {"status": "completed"})


async def stream_tax_response(
    question: str, 
    db_query: TaxIncentiveQuery, 
    deepseek: DeepSeekClient
) -> AsyncGenerator[str, None]:
    """æµå¼è¿”å›ç¨æ”¶ä¼˜æƒ æŸ¥è¯¢ç»“æœ"""
    
    def send_content(content: str) -> str:
        return f"event: message\ndata: {json.dumps({'content': content}, ensure_ascii=False)}\n\n"
    
    # æŸ¥è¯¢æ•°æ®åº“
    results, total_count, query_intent = db_query.search(question, limit=20)
    
    if not results:
        yield send_content("ğŸ“Š **æœ¬åœ°çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ**\n\n")
        yield send_content("æœªæ‰¾åˆ°ç›¸å…³ç¨æ”¶ä¼˜æƒ æ”¿ç­–ã€‚\n\n")
        yield send_content("ğŸ’¡ **å»ºè®®**:\n")
        yield send_content("1. å°è¯•ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯\n")
        yield send_content("2. å’¨è¯¢ç¨åŠ¡ä¸“ä¸šäººå£«\n")
        return
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    yield send_content("ğŸ“Š **æœ¬åœ°çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ**\n\n")
    
    if total_count > len(results):
        yield send_content(f"çŸ¥è¯†åº“å…±æœ‰ **{total_count}** æ¡ç›¸å…³æ”¿ç­–,ä»¥ä¸‹å±•ç¤ºå‰ **{len(results)}** æ¡:\n\n")
        yield send_content("ğŸ’¡ *å¦‚éœ€æŸ¥çœ‹æ›´å¤š,è¯·ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯ç¼©å°èŒƒå›´*\n\n")
    else:
        yield send_content(f"æ‰¾åˆ° **{total_count}** æ¡ç›¸å…³æ”¿ç­–:\n\n")
    
    # æ„å»ºç»“æœæ–‡æœ¬
    results_text = ""
    is_detailed = len(results) <= 10
    
    for idx, result in enumerate(results, 1):
        results_text += f"### æ”¿ç­– {idx}\n"
        results_text += f"- **ç¨ç§**: {result.get('tax_type', 'N/A')}\n"
        results_text += f"- **ä¼˜æƒ é¡¹ç›®**: {result.get('project_name', 'N/A')}\n"
        results_text += f"- **ä¼˜æƒ æ–¹å¼**: {result.get('incentive_method', 'N/A')}\n"
        
        if result.get('qualification'):
            qual = result['qualification']
            if is_detailed or query_intent == "condition":
                if len(qual) > 500:
                    qual = qual[:500] + "..."
            else:
                if len(qual) > 100:
                    qual = qual[:100] + "..."
            results_text += f"- **è®¤å®šæ¡ä»¶**: {qual}\n"
        
        if result.get('detailed_rules'):
            rules = result['detailed_rules']
            if is_detailed:
                if len(rules) > 800:
                    rules = rules[:800] + "..."
            else:
                if len(rules) > 150:
                    rules = rules[:150] + "..."
            results_text += f"- **å…·ä½“è§„å®š**: {rules}\n"
        
        if result.get('legal_basis'):
            basis = result['legal_basis']
            if is_detailed:
                if len(basis) > 400:
                    basis = basis[:400] + "..."
            else:
                if len(basis) > 100:
                    basis = basis[:100] + "..."
            results_text += f"- **æ³•å¾‹ä¾æ®**: {basis}\n"
        
        results_text += "\n"
    
    # æ„å»º DeepSeek prompt
    if query_intent == "condition":
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ç¨æ”¶ä¼˜æƒ æ”¿ç­–æ•°æ®,å›ç­”ç”¨æˆ·é—®é¢˜,é¡»åŒ…å«å…·ä½“ä¼˜æƒ è§„å®šã€ä¼˜æƒ æ–¹å¼ã€æ³•å¾‹ä¾æ®ç­‰å…³é”®ä¿¡æ¯,**é‡ç‚¹çªå‡ºä¼˜æƒ è®¤å®šæ¡ä»¶ã€ç”³è¯·è¦æ±‚ã€æ‰€éœ€èµ„æ–™ç­‰**ã€‚

ç”¨æˆ·é—®é¢˜: {question}

æ”¿ç­–æ•°æ®:
{results_text}

è¦æ±‚:
1. ç”¨æ¸…æ™°çš„Markdownæ ¼å¼å›ç­”
2. **é‡ç‚¹çªå‡ºä¼˜æƒ è®¤å®šæ¡ä»¶ã€ç”³è¯·è¦æ±‚ã€æ‰€éœ€èµ„æ–™ç­‰**
3. å¦‚æœ‰å¤šä¸ªæ”¿ç­–,åˆ†åˆ«è¯´æ˜å„è‡ªçš„æ¡ä»¶å’Œè¦æ±‚
4. è¯­è¨€ç®€æ´ä¸“ä¸š,æ˜“äºç†è§£
5. å¦‚æœéœ€è¦æ›´è¯¦ç»†ä¿¡æ¯,å»ºè®®å’¨è¯¢ç¨åŠ¡ä¸“ä¸šäººå£«

è¯·ç›´æ¥å›ç­”,ä¸è¦é‡å¤é—®é¢˜ã€‚"""
    else:
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ç¨æ”¶ä¼˜æƒ æ”¿ç­–æ•°æ®,å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜: {question}

æ”¿ç­–æ•°æ®:
{results_text}

è¦æ±‚:
1. ç”¨æ¸…æ™°çš„Markdownæ ¼å¼å›ç­”
2. çªå‡ºå…³é”®ä¿¡æ¯(ä¼˜æƒ æ¯”ä¾‹ã€é€‚ç”¨æ¡ä»¶ã€å…·ä½“ä¼˜æƒ è§„å®šã€æ³•å¾‹ä¾æ®ç­‰)
3. å¦‚æœ‰å¤šä¸ªæ”¿ç­–,ç®€è¦è¯´æ˜å®ƒä»¬çš„åŒºåˆ«å’Œé€‚ç”¨åœºæ™¯
4. è¯­è¨€ç®€æ´ä¸“ä¸š,æ˜“äºç†è§£
5. å¦‚æœéœ€è¦æ›´è¯¦ç»†ä¿¡æ¯,å»ºè®®å’¨è¯¢ç¨åŠ¡ä¸“ä¸šäººå£«

è¯·ç›´æ¥å›ç­”,ä¸è¦é‡å¤é—®é¢˜ã€‚"""
    
    messages = [{"role": "user", "content": prompt}]
    
    # æµå¼è¾“å‡º DeepSeek å“åº”
    for chunk in deepseek.chat_completion(messages, stream=True):
        if chunk:
            yield send_content(chunk)
            await asyncio.sleep(0.01)
    
    # æ·»åŠ æ•°æ®æ¥æºæ ‡è¯†
    yield send_content("\n\n---\n")
    yield send_content("*æ•°æ®æ¥æº: æœ¬åœ°ç¨æ”¶ä¼˜æƒ æ”¿ç­–æ•°æ®åº“*\n")


async def stream_financial_response(
    question: str,
    company: Optional[dict],
    financial_query: FinancialQuery,
    deepseek: DeepSeekClient,
    show_chart: bool = True,
    response_mode: str = "detailed"
) -> AsyncGenerator[str, None]:
    """æµå¼è¿”å›è´¢åŠ¡æ•°æ®æŸ¥è¯¢ç»“æœ"""
    
    def send_content(content: str) -> str:
        return f"event: message\ndata: {json.dumps({'content': content}, ensure_ascii=False)}\n\n"
    
    def send_event(event_type: str, data: dict) -> str:
        return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"
    
    try:
        if company:
            # ä½¿ç”¨å‰ç«¯é€‰ä¸­çš„å…¬å¸
            time_range = financial_query.extract_time_range(question)
            metrics = financial_query.extract_metrics(question)
            results = financial_query.execute_query(company['id'], time_range, metrics, question)
            
            if not results:
                yield send_content("ğŸ“Š **ä¼ä¸šè´¢åŠ¡æ•°æ®æŸ¥è¯¢**\n\n")
                yield send_content(f"ğŸ“‹ {company['name']} æš‚æ— ç›¸å…³æ•°æ®\n")
                return
            
            status = "success"
        else:
            # ä»é—®é¢˜ä¸­åŒ¹é…å…¬å¸
            results, company, status = financial_query.search(question)
        
        if status == "company_not_found":
            yield send_content("ğŸ“Š **ä¼ä¸šè´¢åŠ¡æ•°æ®æŸ¥è¯¢**\n\n")
            yield send_content("âŒ æœªæ‰¾åˆ°è¯¥ä¼ä¸š,è¯·æ£€æŸ¥ä¼ä¸šåç§°æ˜¯å¦æ­£ç¡®ã€‚\n\n")
            yield send_content("ğŸ’¡ **ç³»ç»Ÿä¸­çš„ä¼ä¸šåŒ…æ‹¬**:\n")
            for name in financial_query._load_companies().values():
                yield send_content(f"- {name}\n")
            return
        
        if status == "no_data" or not results:
            yield send_content("ğŸ“Š **ä¼ä¸šè´¢åŠ¡æ•°æ®æŸ¥è¯¢**\n\n")
            yield send_content(f"ğŸ“‹ {company['name']} æš‚æ— ç›¸å…³æ•°æ®\n")
            return
        
        # æ˜¾ç¤ºæ ‡é¢˜
        yield send_content("ğŸ“Š **ä¼ä¸šè´¢åŠ¡æ•°æ®æŸ¥è¯¢**\n\n")
        
        # === æ£€æŸ¥æ˜¯å¦éœ€è¦æç¤ºé»˜è®¤å¹³å‡å€¼ ===
        # æ¡ä»¶: 1.æ•°æ®æ˜¯æŒ‰å¹´åˆ†ç»„(ç»“æœä¸­æ²¡æœ‰quarter) 2.æŒ‡æ ‡æ˜¯æ¯”ç‡ç±» 3.é—®é¢˜ä¸­æ²¡æœ‰æ˜ç¡®æŒ‡æ˜"å¹³å‡"ç­‰è¯
        try:
            has_ratio = False
            is_annual = True
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¯”ç‡æŒ‡æ ‡
            for r in results:
                m_name = r.get('metric_name', '')
                # ç®€å•åˆ¤æ–­: åŒ…å«"ç‡", "æ¯”", "burden", "margin"ç­‰
                if any(x in m_name for x in ["ç‡", "æ¯”", "burden", "margin"]):
                    has_ratio = True
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å­£åº¦ä¿¡æ¯ (å¦‚æœä»»ä¸€è¡Œæœ‰å­£åº¦ä¸”ä¸ä¸ºNone/0ï¼Œåˆ™ä¸æ˜¯çº¯å¹´åº¦)
                q = r.get('quarter') or r.get('period_quarter')
                if q:
                    is_annual = False
            
            # æ£€æŸ¥é—®é¢˜å…³é”®è¯
            explicit_keywords = ["å¹³å‡", "æœ€å¤§", "æœ€å°", "æ¯å­£", "å­£åº¦", "æ˜ç»†", "è¶‹åŠ¿", "detail", "avg", "max", "min"]
            has_explicit_intent = any(kw in question for kw in explicit_keywords)
            
            if has_ratio and is_annual and not has_explicit_intent:
                warning_msg = "ğŸ’¡ *ç³»ç»Ÿæç¤º: ç”¨æˆ·æ²¡æœ‰æ˜ç¡®æç¤ºæ¯”ç‡æŒ‡æ ‡æ˜¯æŸ¥è¯¢æ˜ç»†è¿˜æ˜¯å¹³å‡å€¼ã€æœ€å¤§å€¼ç­‰ç»Ÿè®¡å€¼ï¼Œç³»ç»Ÿé»˜è®¤è®¡ç®—å¹³å‡å€¼ï¼›å¦‚æœå¸Œæœ›æ›´ç²¾ç¡®æŸ¥è¯¢ï¼Œè¯·ç»™å‡ºæ˜ç¡®æç¤º*\n\n"
                yield send_content(warning_msg)
                
        except Exception as w_e:
            print(f"Warning logic error: {w_e}")

        # === 1. ç”Ÿæˆè¡¨æ ¼ (è¯¦ç»†/æ ‡å‡†æ¨¡å¼) ===
        if response_mode in ["detailed", "standard"]:
            formatted = financial_query.format_results(results, company)
            yield send_content(formatted)
        
        # === 2. ç”Ÿæˆå›¾è¡¨ (ä»…è¯¦ç»†æ¨¡å¼) ===
        comparison_result = None
        if response_mode == "detailed":
            # å¯¹æ¯”åˆ†æè®¡ç®—
            time_range = financial_query.extract_time_range(question)
            if time_range.get('is_comparison'):
                comparison_result = financial_query.calculate_comparison(results, time_range)
                if comparison_result.get('has_comparison'):
                    formatted_comparison = financial_query.format_comparison(comparison_result, company)
                    yield send_content(formatted_comparison)
            
            # å‘é€å›¾è¡¨æ•°æ® (ä»…å½“å¼€å¯æ˜¾ç¤ºä¸”æ•°æ®è¶³å¤Ÿæ—¶)
            if len(results) >= 2:
                try:
                    # 1. æ•´ç†æ•°æ®ï¼šæŒ‰ metric åˆ†ç»„
                    metrics_map = {} # metric -> { (year, q) -> value }
                    all_periods = set()
                    
                    for r in results:
                        m = r['metric_name']
                        p = (r['year'], r.get('quarter'))
                        all_periods.add(p)
                        if m not in metrics_map:
                            metrics_map[m] = {}
                        metrics_map[m][p] = r['value']
                    
                    # æ’åº periods
                    sorted_periods = sorted(list(all_periods), key=lambda x: (x[0], x[1] or 0))
                    labels = []
                    for year, quarter in sorted_periods:
                        labels.append(f"{year}å¹´" + (f"Q{quarter}" if quarter else ""))
                    
                    unique_metrics = list(metrics_map.keys())
                    
                    # 2. å†³ç­–ï¼šå•æŒ‡æ ‡ vs å¤šæŒ‡æ ‡
                    if len(unique_metrics) == 1:
                        # === å•æŒ‡æ ‡ï¼šä½¿ç”¨è¯¦ç»†å¯¹æ¯”å›¾è¡¨ (Combo Chart) ===
                        metric = unique_metrics[0]
                        values = []
                        growth_amounts = []
                        growth_rates = []
                        
                        prev_val = None
                        for p in sorted_periods:
                            val = metrics_map[metric].get(p)
                            values.append(val or 0)
                            
                            if prev_val is not None and prev_val != 0 and val is not None:
                                growth = val - prev_val
                                growth_pct = (growth / abs(prev_val)) * 100
                                growth_wan = growth / 10000 if abs(growth) >= 10000 else growth
                                growth_amounts.append(round(growth_wan, 2))
                                growth_rates.append(round(growth_pct, 2))
                            else:
                                growth_amounts.append(None)
                                growth_rates.append(None)
                            
                            prev_val = val
                        
                        # å¦‚æœæœ‰å¯¹æ¯”ä¿¡æ¯(growth_ratesä¸å…¨ä¸ºNone)ï¼Œä½¿ç”¨Comboå›¾ï¼Œå¦åˆ™æ™®é€šBarå›¾
                        if any(g is not None for g in growth_rates):
                            chart_data = {
                                "chartType": "combo",
                                "title": f"{company['name']} {metric}è¶‹åŠ¿åˆ†æ",
                                "labels": labels,
                                "datasets": [
                                    {
                                        "type": "bar",
                                        "label": metric,  # æ˜¾ç¤ºåŸå§‹æŒ‡æ ‡å
                                        "data": values,   # æ˜¾ç¤ºåŸå§‹æ•°å€¼
                                        "yAxisID": "y",
                                        "backgroundColor": "rgba(54, 162, 235, 0.8)",
                                        "borderColor": "rgba(54, 162, 235, 1)"
                                    },
                                    {
                                        "type": "bar",
                                        "label": "å¢é•¿ç‡(%)",
                                        "data": growth_rates,
                                        "yAxisID": "y1",
                                        "borderColor": "rgba(255, 159, 64, 1)",
                                        "backgroundColor": "rgba(255, 159, 64, 0.7)", # Slightly more opaque for bar
                                    }
                                ],
                                "options": {
                                    "scales": {
                                        "y": {"type": "linear", "position": "left", "title": {"display": True, "text": metric}}, 
                                        "y1": {"type": "linear", "position": "right", "title": {"display": True, "text": "å¢é•¿ç‡(%)"}, "grid": {"drawOnChartArea": False}}
                                    }
                                }
                            }
                        else:
                            chart_data = {
                                "chartType": "bar",
                                "title": f"{company['name']} {metric}",
                                "labels": labels,
                                "datasets": [{"label": metric, "data": values}]
                            }
                        yield send_event("chart", chart_data)
                        
                    else:
                        # === å¤šæŒ‡æ ‡ï¼šå‘é€ä¸¤ä¸ªå›¾è¡¨ (ç»å¯¹å€¼å¯¹æ¯” + å¢é•¿ç‡å¯¹æ¯”) ===
                        # é™åˆ¶æŒ‡æ ‡æ•°é‡ï¼Œé˜²æ­¢ç”±äºå®½è¡¨å¯¼è‡´å›¾è¡¨ä¸å¯è¯» (e.g. top 5)
                        top_metrics = unique_metrics[:5] 
                        
                        colors = [
                            "rgba(54, 162, 235, 0.8)", "rgba(255, 99, 132, 0.8)", 
                            "rgba(255, 206, 86, 0.8)", "rgba(75, 192, 192, 0.8)", 
                            "rgba(153, 102, 255, 0.8)"
                        ]
                        
                        border_colors = [
                            "rgba(54, 162, 235, 1)", "rgba(255, 99, 132, 1)", 
                            "rgba(255, 206, 86, 1)", "rgba(75, 192, 192, 1)", 
                            "rgba(153, 102, 255, 1)"
                        ]
                        
                        # === å›¾è¡¨1: ç»å¯¹å€¼å¯¹æ¯” (æŸ±çŠ¶å›¾) ===
                        value_datasets = []
                        for idx, metric in enumerate(top_metrics):
                            data_points = []
                            for p in sorted_periods:
                                val = metrics_map[metric].get(p, 0)
                                data_points.append(val or 0)
                            
                            value_datasets.append({
                                "type": "bar",
                                "label": metric,
                                "data": data_points,
                                "backgroundColor": colors[idx % len(colors)],
                                "borderColor": border_colors[idx % len(border_colors)],
                                "borderWidth": 1
                            })
                        
                        chart1_data = {
                            "chartType": "bar",
                            "title": f"{company['name']} æŒ‡æ ‡ç»å¯¹å€¼å¯¹æ¯” ({len(top_metrics)}/{len(unique_metrics)})",
                            "labels": labels,
                            "datasets": value_datasets
                        }
                        yield send_event("chart", chart1_data)
                        
                        # === å›¾è¡¨2: å¢é•¿ç‡å¯¹æ¯” (æŸ±çŠ¶å›¾) ===
                        growth_datasets = []
                        for idx, metric in enumerate(top_metrics):
                            growth_rates = []
                            prev_val = None
                            
                            for p in sorted_periods:
                                val = metrics_map[metric].get(p)
                                
                                if prev_val is not None and prev_val != 0 and val is not None:
                                    growth_pct = ((val - prev_val) / abs(prev_val)) * 100
                                    growth_rates.append(round(growth_pct, 2))
                                else:
                                    growth_rates.append(None)
                                
                                prev_val = val
                            
                            growth_datasets.append({
                                "type": "bar",
                                "label": metric,
                                "data": growth_rates,
                                "backgroundColor": colors[idx % len(colors)],
                                "borderColor": border_colors[idx % len(border_colors)],
                                "borderWidth": 1
                            })
                        
                        chart2_data = {
                            "chartType": "bar",
                            "title": f"{company['name']} æŒ‡æ ‡å¢é•¿ç‡å¯¹æ¯” (%) ({len(top_metrics)}/{len(unique_metrics)})",
                            "labels": labels,
                            "datasets": growth_datasets,
                            "options": {
                                "scales": {
                                    "y": {
                                        "ticks": {
                                            "callback": "function(value) { return value + '%'; }"
                                        }
                                    }
                                }
                            }
                        }
                        yield send_event("chart", chart2_data)
                        
                except Exception as e:
                    print(f"âš ï¸ å›¾è¡¨æ•°æ®å‘é€å¤±è´¥: {e}")

        # === 3. åˆ†ææ€»ç»“ (è¯¦ç»†/æ ‡å‡†æ¨¡å¼) ===
        if response_mode in ["detailed", "standard"]:
            if len(results) > 2:
                yield send_event("summary", {"content": "\n**åˆ†ææ€»ç»“**:\n"})
                results_text = financial_query.format_results(results, company) # é‡æ–°è·å–æ ¼å¼åŒ–æ–‡æœ¬
                prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¼ä¸šè´¢åŠ¡æ•°æ®,ç®€è¦åˆ†ææ€»ç»“ã€‚ç”¨æˆ·é—®é¢˜: {question}
æ•°æ®:
{results_text}
è¦æ±‚: æ ¹æ®è¿”å›çš„æ•°æ®é‡å¤§å°,ç”¨5-20å¥è¯æ€»ç»“æ•°æ®ç‰¹ç‚¹å’Œè¶‹åŠ¿ï¼Œåˆ†æå¯èƒ½å­˜åœ¨çš„é£é™©; å¦‚æœ‰æ˜æ˜¾è¶‹åŠ¿å˜åŒ–,ç®€è¦åˆ†æå¯èƒ½åŸå› ï¼›å¦‚æœ‰ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸ŠæŒ‡æ ‡ä¸”ç›¸äº’å¯ä»¥å¯¹æ¯”åˆ†æï¼Œåˆ™éœ€åˆ†ææ˜¯å¦å­˜åœ¨èƒŒç¦»ã€‚ä¸è¦é‡å¤åŸå§‹æ•°æ®ã€‚"""
                
                messages = [{"role": "user", "content": prompt}]
                for chunk in deepseek.chat_completion(messages, stream=True):
                    if chunk:
                        yield send_event("summary", {"content": chunk})
                        await asyncio.sleep(0.01)
        
        # === 4. ç®€æŠ¥æ¨¡å¼ (Concise) ===
        elif response_mode == "concise":
            # ä»…ç”Ÿæˆè‡ªç„¶è¯­è¨€æ€»ç»“ï¼Œæ— è¡¨æ ¼æ— å›¾è¡¨
            
            # å°† results è½¬æ¢ä¸ºç®€åŒ–æ–‡æœ¬ä¾› LLM é˜…è¯»
            raw_data_text = f"ä¼ä¸š: {company['name']}\næ•°æ®:\n"
            for r in results:
                metric = r.get('metric_name')
                year = r.get('year')
                qtr = r.get('quarter')
                val = r.get('value')
                unit = r.get('unit', 'å…ƒ')
                if qtr:
                    time_label = f"{year}å¹´Q{qtr}"
                else:
                    time_label = f"{year}å¹´"
                
                # ç®€å•æ•°å€¼æ ¼å¼åŒ–
                if val is not None and isinstance(val, (int, float)):
                    if abs(val) > 100000000:
                        val_str = f"{val/100000000:.2f}äº¿"
                    elif abs(val) > 10000:
                        val_str = f"{val/10000:.2f}ä¸‡"
                    else:
                        val_str = f"{val:.2f}"
                else:
                    val_str = str(val)
                
                raw_data_text += f"- {time_label} {metric}: {val_str} {unit}\n"
            
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è´¢åŠ¡æŸ¥è¯¢ç»“æœï¼Œç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜: {question}

æŸ¥è¯¢åˆ°çš„åŸå§‹æ•°æ®:
{raw_data_text}

è¦æ±‚:
æ ¹æ®è¿”å›çš„æ•°æ®é‡å¤§å°,ç”¨5-20å¥è¯æ€»ç»“æ•°æ®ç‰¹ç‚¹å’Œè¶‹åŠ¿ï¼Œåˆ†æå¯èƒ½å­˜åœ¨çš„é£é™©; å¦‚æœ‰æ˜æ˜¾è¶‹åŠ¿å˜åŒ–,ç®€è¦åˆ†æå¯èƒ½åŸå› ï¼›å¦‚æœ‰ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸ŠæŒ‡æ ‡ä¸”ç›¸äº’å¯ä»¥å¯¹æ¯”åˆ†æï¼Œåˆ™éœ€åˆ†ææ˜¯å¦å­˜åœ¨èƒŒç¦»ã€‚
**ä¸è¦ä½¿ç”¨è¡¨æ ¼** ï¼›æ§åˆ¶ç¯‡å¹…ï¼Œä¾¿äºç§»åŠ¨ç«¯æŸ¥çœ‹ã€‚

è¯·ç›´æ¥å›ç­”ã€‚"""
            
            messages = [{"role": "user", "content": prompt}]
            
            # æµå¼è¾“å‡ºæ€»ç»“
            for chunk in deepseek.chat_completion(messages, stream=True):
                if chunk:
                    yield send_content(chunk)
                    await asyncio.sleep(0.01)

        # æ·»åŠ æ•°æ®æ¥æºæ ‡è¯†
        yield send_content("\n\n---\n")
        yield send_content("*æ•°æ®æ¥æº: ä¼ä¸šè´¢åŠ¡æ•°æ®åº“*\n")
    
    except Exception as e:
        yield send_content(f"\n\nâš ï¸ æŸ¥è¯¢å‡ºé”™: {str(e)}\n")



def parse_sse_line(line: str):
    """è§£æ SSE è¡Œ"""
    line = line.strip()
    if not line:
        return None, None
    if line.startswith('event:'):
        return line[6:].strip(), None
    if line.startswith('data:'):
        try:
            return None, json.loads(line[5:].strip())
        except:
            return None, None
    return None, None


async def stream_coze_response(question: str) -> AsyncGenerator[str, None]:
    """æµå¼è°ƒç”¨ Coze API"""
    
    def send_content(content: str) -> str:
        return f"event: message\ndata: {json.dumps({'content': content}, ensure_ascii=False)}\n\n"
    
    headers = {
        "Authorization": f"Bearer {PAT_TOKEN}",
        "Content-Type": "application/json; charset=utf-8",
        "Accept": "text/event-stream",
        "User-Agent": "Mozilla/5.0"
    }
    payload = {
        "bot_id": BOT_ID,
        "user_id": USER_ID,
        "stream": True,
        "auto_save_history": True,
        "additional_messages": [{"role": "user", "content": question, "content_type": "text"}],
        "temperature": 0.7,
        "max_tokens": 2000
    }
    
    try:
        response = requests.post(
            "https://api.coze.cn/v3/chat",
            headers=headers,
            json=payload,
            stream=True,
            timeout=180,
            verify=False
        )
        
        if response.status_code != 200:
            yield send_content(f"âŒ API é”™è¯¯: {response.status_code}\n")
            return
        
        current_event = None
        for chunk in response.iter_content(chunk_size=1024):
            if not chunk:
                continue
            
            chunk_str = chunk.decode('utf-8', errors='ignore')
            lines = chunk_str.split('\n')
            
            for line in lines:
                event_type, data = parse_sse_line(line)
                if event_type:
                    current_event = event_type
                if data and current_event == "conversation.message.delta":
                    if data.get("role") == "assistant" and data.get("type") == "answer":
                        content = data.get("content", "")
                        if content:
                            yield send_content(content)
                            await asyncio.sleep(0.01)
    
    except Exception as e:
        yield send_content(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}\n")


@router.post("/chat")
async def chat_stream(request: ChatRequest, current_user: dict = Depends(get_current_user)):
    """
    æ™ºèƒ½å¯¹è¯ APIï¼ˆSSE æµå¼è¾“å‡ºï¼‰
    
    - è‡ªåŠ¨è¯†åˆ«æ„å›¾å¹¶è·¯ç”±åˆ°å¯¹åº”æ¨¡å—
    - æ”¯æŒç¨æ”¶ä¼˜æƒ æŸ¥è¯¢ã€è´¢åŠ¡æ•°æ®æŸ¥è¯¢ã€é€šç”¨å’¨è¯¢
    - è¿”å› SSE æµå¼å“åº”
    """
    user_id = str(current_user['id'])
    return StreamingResponse(
        generate_sse_response(
            question=request.question,
            user_id=user_id,
            company_id=request.company_id,
            enable_routing=request.enable_routing,
            show_chart=request.show_chart,
            response_mode=request.response_mode
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.post("/chat/sync")
async def chat_sync(request: ChatRequest) -> ChatResponse:
    """
    åŒæ­¥å¯¹è¯ APIï¼ˆéæµå¼ï¼Œç”¨äºæµ‹è¯•ï¼‰
    """
    classifier, db_query, deepseek, financial_query = get_modules()
    
    # ç®€åŒ–ç‰ˆåŒæ­¥å“åº”
    intent = classifier.classify(request.question)
    
    if intent == "tax_incentive":
        results, total_count, _ = db_query.search(request.question, limit=5)
        if results:
            content = f"æ‰¾åˆ° {total_count} æ¡ç›¸å…³ç¨æ”¶ä¼˜æƒ æ”¿ç­–ã€‚"
        else:
            content = "æœªæ‰¾åˆ°ç›¸å…³ç¨æ”¶ä¼˜æƒ æ”¿ç­–ã€‚"
        return ChatResponse(content=content, source="tax_incentive")
    
    elif intent == "financial_data":
        results, company, status = financial_query.search(request.question)
        if status == "success" and results:
            if request.response_mode == "concise":
                # ç®€ç•¥æ¨¡å¼ï¼šåªè¿”å›ç®€çŸ­æ€»ç»“
                content = f"å·²æ‰¾åˆ° {company['name']} çš„ç›¸å…³æ•°æ®ï¼Œå…±æœ‰ {len(results)} æ¡è®°å½•ã€‚"
            else:
                content = financial_query.format_results(results, company)
        else:
            content = "æœªæ‰¾åˆ°ç›¸å…³è´¢åŠ¡æ•°æ®ã€‚"
        return ChatResponse(content=content, source="financial")
    
    else:
        content = "è¯·ä½¿ç”¨æµå¼ API (/api/chat) è·å–å®Œæ•´å›ç­”ã€‚"
        return ChatResponse(content=content, source="coze")


@router.get("/chat/history")
async def get_history_api(limit: int = 50, current_user: dict = Depends(get_current_user)):
    """è·å–èŠå¤©å†å² (ä¸»çª—å£æ¶ˆæ¯)"""
    user_id = str(current_user['id'])
    return get_chat_history(user_id, limit)


@router.get("/chat/history-items")
async def get_history_items_api(limit: int = 50, current_user: dict = Depends(get_current_user)):
    """è·å–å†å²è®°å½•åˆ—è¡¨ (ä¾§è¾¹æ )"""
    user_id = str(current_user['id'])
    return get_history_items(user_id, limit)


class DeleteHistoryRequest(BaseModel):
    message_ids: Optional[list] = None
    delete_all: bool = False
    target: str = "chat"  # "chat" for main window, "history" for sidebar
    content_list: Optional[list] = None  # For deleting by content


@router.delete("/chat/history")
async def delete_history_api(request: DeleteHistoryRequest, current_user: dict = Depends(get_current_user)):
    """åˆ é™¤èŠå¤©å†å² (è½¯åˆ é™¤)"""
    user_id = str(current_user['id'])
    
    # å¦‚æœæ˜¯æŒ‰å†…å®¹åˆ é™¤ (ä¾§è¾¹æ )
    if request.content_list:
        delete_history_by_content(user_id, request.content_list)
        return {"status": "success"}
    
    # æŒ‰IDæˆ–å…¨éƒ¨åˆ é™¤
    if request.delete_all:
        delete_user_history(user_id, target=request.target)
    elif request.message_ids:
        delete_user_history(user_id, request.message_ids, target=request.target)
    return {"status": "success"}
